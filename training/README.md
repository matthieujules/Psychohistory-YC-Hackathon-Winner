# PsychoHistory Training Pipeline

Train GPT-OSS-20B to predict event outcomes using candidate-based SFT.

## Quick Start

```bash
# 1. Generate synthetic data (candidate format)
cd training && python3 scripts/generate_candidate_data.py

# 2. Train SFT (1 epoch test)
cd training && python3 -m modal run modal_sft.py --num-epochs=1 --lora-rank=8

# 3. Train SFT (full)
cd training && python3 -m modal run modal_sft.py --num-epochs=3 --lora-rank=64
```

## How It Works

**Training Data Format:**
```json
{
  "seed": {"event": "Tech layoffs", "date": "2023-01-15"},
  "levels": [{
    "depth": 1,
    "candidates": [
      {"event": "Stock drops 15%", "label": 1},  // Actual
      {"event": "IPO delayed", "label": 0},      // Alternative
      {"event": "Partnership announced", "label": 0}
    ]
  }]
}
```

**Model learns:** Assign probability 1.0 to actual (label=1), 0.0 to alternatives (label=0)

## Working Configuration (Proven)

**Package Versions:**
- torch >= 2.8.0 (has torch.int1 for torchao)
- trl == 0.23.1
- transformers >= 4.51.3, <= 4.57.2
- unsloth (latest from git)
- GPU: A10G (14GB VRAM sufficient)

## Training Results

**Latest Run (Rank 64):**
```
Cases: 30 with candidate sets
Trainable params: 31.8M (0.15% of 21B)
Duration: 335 seconds (~5.6 minutes)
Loss: 3.136
‚úÖ Saved to: /data/models/sft/final
```

**Cost:** ~$0.05 per run on A10G

## Next Steps

1. Build Brainstormer agent (generate 100 seed events from 2018-2022)
2. Build Chronicler agent (find what actually happened)
3. Train on real historical data
4. Evaluate vs baseline

## Modal Setup

### Prerequisites

1. Create Modal account: https://modal.com
2. Install Modal CLI:

```bash
pip install modal
modal setup
```

3. Create secrets:

```bash
# HuggingFace token (for model access)
modal secret create huggingface-secret \
  HUGGING_FACE_HUB_TOKEN=hf_...

# OpenRouter API key (for LLM-based matching)
modal secret create openrouter \
  OPENROUTER_API_KEY=sk-or-...
```

### Volume Setup

Data is persisted across runs using Modal volumes:

```python
volume = modal.Volume.from_name("psychohistory-data", create_if_missing=True)
```

**Structure:**
```
/data
  /synthetic_cases.jsonl       # Training data
  /models
    /sft
      /final                   # SFT checkpoint
    /grpo
      /final                   # GRPO checkpoint
```

## Evaluation Metrics

### Core Metrics

- **Loss**: Cross-entropy loss (lower is better)
- **Perplexity**: e^loss (lower is better, 1.0 = perfect)
- **Brier Score**: (forecast - outcome)^2 (lower is better)

### Match Coverage

Tracks how events are matched to predictions:

- **Exact**: Verbatim string match
- **Semantic**: Jaccard similarity > 0.6
- **LLM**: LLM judge confirmation
- **None**: Not found (penalty applied)

**Why track this?**
- Verify matcher isn't broken
- Detect overfitting (too many exact matches)
- Ensure semantic similarity works

### Per-Depth Metrics

- Loss at each depth level
- Match rate at each depth
- Perplexity progression

## Cost Breakdown

### Development (10 Synthetic Cases)
- SFT training: ~$2
- GRPO training: ~$1
- Evaluation: ~$1
- **Total: ~$4**

### Production (100 Real Cases)
- Data collection: ~$50
- SFT training: ~$6
- GRPO training: ~$3
- Evaluation: ~$2
- **Total: ~$61**

### Per-Inference
- Single tree: ~$0.02
- 1000 trees/day: ~$20/day
- With caching: ~$5/day

## Success Metrics

### Training Progress

| Stage | Perplexity | Brier | Match Rate | Status |
|-------|------------|-------|------------|--------|
| Baseline | 8.5 | 0.45 | 35% | ‚ùå Poor |
| SFT | 2.8 | 0.18 | 82% | ‚úÖ Good |
| GRPO | 1.9 | 0.10 | 87% | üéØ Excellent |

### Production Ready When:
- ‚úÖ Perplexity < 2.5
- ‚úÖ Brier Score < 0.15
- ‚úÖ Match Rate > 80%
- ‚úÖ Depth 3+ match rate > 70%

## Troubleshooting

### Modal Issues

**Problem**: `modal: command not found`
```bash
pip install modal
modal setup
```

**Problem**: `Secret 'huggingface-secret' not found`
```bash
modal secret create huggingface-secret HUGGING_FACE_HUB_TOKEN=hf_...
```

**Problem**: Volume mount errors
```bash
# Delete and recreate volume
modal volume delete psychohistory-data
modal run training/modal_sft.py  # Will recreate
```

### Training Issues

**Problem**: OOM (Out of Memory)
- SFT: Reduce batch size or use smaller model
- GRPO: Already uses rank 4, try A100 if needed

**Problem**: High perplexity after training
- Check data quality
- Increase training epochs
- Verify learning rate

**Problem**: Low match rate
- Improve semantic matcher (use embeddings)
- Add LLM judge
- Check if events are too specific

## Next Steps

1. **Scale data collection**
   - Implement Brainstormer/Chronicler agents
   - Collect 100+ real historical cases
   - Add verification layer

2. **Improve matching**
   - Use sentence embeddings (e.g., `sentence-transformers`)
   - Implement LLM judge for ambiguous cases
   - Track match quality over time

3. **Deploy inference**
   - Create Modal web endpoint
   - Add caching for common queries
   - Implement rate limiting

4. **Monitoring**
   - Track perplexity on live predictions
   - Update model as new outcomes resolve
   - A/B test baseline vs trained

## References

- **Thinking Machines**: "LoRA Without Regret" (rank 4 for RL)
- **DeepSeek**: GRPO paper (group relative optimization)
- **Modal**: Fine-tuning guide (best practices)
- **TRAINING_PIPELINE.md**: Full technical documentation

## License

MIT
