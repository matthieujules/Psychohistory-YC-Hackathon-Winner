# PsychoHistory Training Pipeline

Train models to output accurate probability trees by learning from historical events with known outcomes.

## Quick Start

```bash
# 1. Generate synthetic data
python3 training/scripts/generate_synthetic_data.py

# 2. Test evaluation pipeline
python3 training/evaluation/evaluator.py

# 3. Run full pipeline (requires Modal setup)
python3 training/run_pipeline.py
```

## Architecture Overview

```
training/
‚îú‚îÄ‚îÄ TRAINING_PIPELINE.md       # Comprehensive pipeline documentation
‚îú‚îÄ‚îÄ README.md                   # This file
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ synthetic_cases.jsonl  # Training data
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ generate_synthetic_data.py  # Data generator
‚îú‚îÄ‚îÄ evaluation/
‚îÇ   ‚îî‚îÄ‚îÄ evaluator.py           # Evaluation with match coverage
‚îú‚îÄ‚îÄ models/                    # Saved checkpoints (Modal volume)
‚îú‚îÄ‚îÄ results/                   # Evaluation results
‚îú‚îÄ‚îÄ modal_sft.py              # SFT training (rank 64)
‚îú‚îÄ‚îÄ modal_grpo.py             # GRPO training (rank 4)
‚îú‚îÄ‚îÄ inference.py              # Hot-swappable inference
‚îî‚îÄ‚îÄ run_pipeline.py           # End-to-end orchestration
```

## Pipeline Steps

### 1. Data Generation

Generate synthetic historical cases for testing:

```python
from scripts.generate_synthetic_data import generate_synthetic_dataset

cases = generate_synthetic_dataset(num_cases=10)
```

Each case includes:
- Seed event (what happened)
- Outcome chain (sequence of consequences)
- Dates and timeframes

### 2. SFT Training (Phase 1)

Supervised fine-tuning with LoRA rank 64:

```bash
modal run training/modal_sft.py
```

**Configuration:**
- LoRA Rank: 64 (higher for learning)
- GPU: A100 40GB
- Learning Rate: 3e-4 (10x higher than full FT)
- Duration: ~2-3 hours
- Cost: ~$6-9

**Expected improvement:**
- Before: Perplexity ~8.5
- After: Perplexity ~2.8

### 3. GRPO Training (Phase 2)

Group Relative Policy Optimization with ultra-low rank:

```bash
modal run training/modal_grpo.py
```

**Configuration:**
- LoRA Rank: 4 (RL needs minimal capacity!)
- GPU: A10G 24GB (cheaper!)
- Learning Rate: 5e-4
- Duration: ~3-4 hours
- Cost: ~$2-3

**Expected improvement:**
- Before GRPO: Perplexity ~2.8
- After GRPO: Perplexity ~1.9

### 4. Evaluation

Evaluate all models with match coverage tracking:

```python
from evaluation.evaluator import TreeEvaluator, print_metrics
from inference import ProbabilityTreeInference

# Initialize
inference = ProbabilityTreeInference()
evaluator = TreeEvaluator()

# Load adapter
inference.load_adapter("/path/to/checkpoint", "my-model")

# Generate tree
tree = inference.generate_tree("Brexit vote passes", "52% leave")

# Evaluate
metrics = evaluator.evaluate(tree, ground_truth)
print_metrics(metrics)
```

**Metrics tracked:**
- Loss & Perplexity
- Brier score
- Match coverage (exact/semantic/LLM/none)
- Per-depth breakdown

### 5. Hot-Swapping Models

Compare baseline vs trained models:

```python
from inference import ProbabilityTreeInference

inference = ProbabilityTreeInference()

# Baseline
inference.load_adapter(None)
baseline_tree = inference.generate_tree(seed_event, context)

# SFT
inference.load_adapter("/data/models/sft/final", "sft")
sft_tree = inference.generate_tree(seed_event, context)

# GRPO
inference.load_adapter("/data/models/grpo/final", "grpo")
grpo_tree = inference.generate_tree(seed_event, context)
```

## Data Format

### Input: Historical Case

```json
{
  "case_id": "brexit_2016",
  "seed_event": "Brexit vote passes",
  "seed_date": "2016-06-23",
  "context": "52% leave, 48% remain",
  "domain": "Geopolitics",
  "outcome_chain": [
    {
      "depth": 1,
      "event": "Article 50 triggered",
      "date": "2017-03-29",
      "timeframe_months": 9
    },
    {
      "depth": 2,
      "event": "Theresa May resigns",
      "date": "2019-07-24",
      "timeframe_months": 28
    }
  ]
}
```

### Output: Probability Tree

```json
{
  "event": "Brexit vote passes",
  "probability": 1.0,
  "children": [
    {
      "event": "Article 50 triggered",
      "probability": 0.65,
      "children": [
        {
          "event": "Theresa May resigns",
          "probability": 0.40,
          "children": []
        }
      ]
    }
  ]
}
```

## Modal Setup

### Prerequisites

1. Create Modal account: https://modal.com
2. Install Modal CLI:

```bash
pip install modal
modal setup
```

3. Create secrets:

```bash
# HuggingFace token (for model access)
modal secret create huggingface-secret \
  HUGGING_FACE_HUB_TOKEN=hf_...

# OpenRouter API key (for LLM-based matching)
modal secret create openrouter \
  OPENROUTER_API_KEY=sk-or-...
```

### Volume Setup

Data is persisted across runs using Modal volumes:

```python
volume = modal.Volume.from_name("psychohistory-data", create_if_missing=True)
```

**Structure:**
```
/data
  /synthetic_cases.jsonl       # Training data
  /models
    /sft
      /final                   # SFT checkpoint
    /grpo
      /final                   # GRPO checkpoint
```

## Evaluation Metrics

### Core Metrics

- **Loss**: Cross-entropy loss (lower is better)
- **Perplexity**: e^loss (lower is better, 1.0 = perfect)
- **Brier Score**: (forecast - outcome)^2 (lower is better)

### Match Coverage

Tracks how events are matched to predictions:

- **Exact**: Verbatim string match
- **Semantic**: Jaccard similarity > 0.6
- **LLM**: LLM judge confirmation
- **None**: Not found (penalty applied)

**Why track this?**
- Verify matcher isn't broken
- Detect overfitting (too many exact matches)
- Ensure semantic similarity works

### Per-Depth Metrics

- Loss at each depth level
- Match rate at each depth
- Perplexity progression

## Cost Breakdown

### Development (10 Synthetic Cases)
- SFT training: ~$2
- GRPO training: ~$1
- Evaluation: ~$1
- **Total: ~$4**

### Production (100 Real Cases)
- Data collection: ~$50
- SFT training: ~$6
- GRPO training: ~$3
- Evaluation: ~$2
- **Total: ~$61**

### Per-Inference
- Single tree: ~$0.02
- 1000 trees/day: ~$20/day
- With caching: ~$5/day

## Success Metrics

### Training Progress

| Stage | Perplexity | Brier | Match Rate | Status |
|-------|------------|-------|------------|--------|
| Baseline | 8.5 | 0.45 | 35% | ‚ùå Poor |
| SFT | 2.8 | 0.18 | 82% | ‚úÖ Good |
| GRPO | 1.9 | 0.10 | 87% | üéØ Excellent |

### Production Ready When:
- ‚úÖ Perplexity < 2.5
- ‚úÖ Brier Score < 0.15
- ‚úÖ Match Rate > 80%
- ‚úÖ Depth 3+ match rate > 70%

## Troubleshooting

### Modal Issues

**Problem**: `modal: command not found`
```bash
pip install modal
modal setup
```

**Problem**: `Secret 'huggingface-secret' not found`
```bash
modal secret create huggingface-secret HUGGING_FACE_HUB_TOKEN=hf_...
```

**Problem**: Volume mount errors
```bash
# Delete and recreate volume
modal volume delete psychohistory-data
modal run training/modal_sft.py  # Will recreate
```

### Training Issues

**Problem**: OOM (Out of Memory)
- SFT: Reduce batch size or use smaller model
- GRPO: Already uses rank 4, try A100 if needed

**Problem**: High perplexity after training
- Check data quality
- Increase training epochs
- Verify learning rate

**Problem**: Low match rate
- Improve semantic matcher (use embeddings)
- Add LLM judge
- Check if events are too specific

## Next Steps

1. **Scale data collection**
   - Implement Brainstormer/Chronicler agents
   - Collect 100+ real historical cases
   - Add verification layer

2. **Improve matching**
   - Use sentence embeddings (e.g., `sentence-transformers`)
   - Implement LLM judge for ambiguous cases
   - Track match quality over time

3. **Deploy inference**
   - Create Modal web endpoint
   - Add caching for common queries
   - Implement rate limiting

4. **Monitoring**
   - Track perplexity on live predictions
   - Update model as new outcomes resolve
   - A/B test baseline vs trained

## References

- **Thinking Machines**: "LoRA Without Regret" (rank 4 for RL)
- **DeepSeek**: GRPO paper (group relative optimization)
- **Modal**: Fine-tuning guide (best practices)
- **TRAINING_PIPELINE.md**: Full technical documentation

## License

MIT
